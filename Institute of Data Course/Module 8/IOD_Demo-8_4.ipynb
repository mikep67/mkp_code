{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"DSIA Demo-8_4.ipynb","provenance":[],"collapsed_sections":[]},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"}},"cells":[{"cell_type":"markdown","metadata":{"id":"El6Q2WYJqAjw","colab_type":"text"},"source":["<div>\n","<img src=https://www.institutedata.com/wp-content/uploads/2019/10/iod_h_tp_primary_c.svg width=\"300\">\n","</div>"]},{"cell_type":"markdown","metadata":{"id":"_-Y1QLrXqAjz","colab_type":"text"},"source":["# Demo 8.4: Stacking\n","\n","INSTRUCTIONS:\n","\n","- Run the cells\n","- Observe and understand the results\n","- Answer the questions"]},{"cell_type":"markdown","metadata":{"id":"ye0DdBIEqAj2","colab_type":"text"},"source":["This is an excerpt from the [Ensemble Learning to Improve Machine Learning Results-How ensemble methods work: bagging, boosting and stacking](https://blog.statsbot.co/ensemble-learning-d1dcd548e936) by **Vadim Smolyakov**."]},{"cell_type":"markdown","metadata":{"id":"68MDqICRqAj4","colab_type":"text"},"source":["## Stacking\n","**Stacking** is an ensemble learning technique that combines multiple classification or regression models via a meta-classifier or a meta-regressor. The base level models are trained based on complete training set then the meta-model is trained on the outputs of base level model as features. The base level often consists of different learning algorithms and therefore stacking ensembles are often heterogeneous."]},{"cell_type":"code","metadata":{"id":"oeeOjXkSqAj6","colab_type":"code","colab":{}},"source":["## Import Libraries\n","\n","import itertools\n","import numpy as np\n","\n","%matplotlib inline\n","import matplotlib.pyplot as plt\n","import matplotlib.gridspec as gridspec\n","import seaborn as sns\n","\n","from sklearn import datasets\n","\n","from sklearn.ensemble import RandomForestClassifier\n","from sklearn.linear_model import LogisticRegression\n","from sklearn.model_selection import cross_val_score, train_test_split\n","from sklearn.naive_bayes import GaussianNB \n","from sklearn.neighbors import KNeighborsClassifier\n","\n","from mlxtend.classifier import StackingClassifier\n","from mlxtend.plotting import plot_learning_curves\n","from mlxtend.plotting import plot_decision_regions"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"70k4lJOZqAkA","colab_type":"text"},"source":["## Load data"]},{"cell_type":"code","metadata":{"id":"dKVMp6q5qAkB","colab_type":"code","colab":{}},"source":["## Loading the dataset\n","\n","iris = datasets.load_iris()\n","\n","# picking just the first two features\n","X = iris.data[:, 1:3]\n","# target\n","y = iris.target"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"mLZsVHN2qAkG","colab_type":"code","colab":{}},"source":["## Check the data\n","\n","# About data\n","print(X.shape)\n","print(X[:5])"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"mcUA_dIiqAkM","colab_type":"code","colab":{}},"source":["# About target\n","print(y.shape)\n","print(y[:5])"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"Hnib-Ux8qAkR","colab_type":"text"},"source":["## Modelling"]},{"cell_type":"code","metadata":{"id":"zviC8A9zqAkT","colab_type":"code","colab":{}},"source":["np.random.seed(0)\n","clf1 = KNeighborsClassifier(n_neighbors = 1)\n","clf2 = RandomForestClassifier(n_estimators = 10, random_state = 1)\n","clf3 = GaussianNB()\n","lr = LogisticRegression(multi_class = 'auto', solver = 'lbfgs')\n","sclf = StackingClassifier(\n","    classifiers = [clf1, clf2, clf3],\n","    meta_classifier = lr)"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"ar_uU5ZuqAkW","colab_type":"text"},"source":["## Presenting results"]},{"cell_type":"code","metadata":{"id":"MmkT_objqAkX","colab_type":"code","colab":{}},"source":["label = ['K-NN', 'Random Forest', 'Naïve Bayes', 'Stacking Classifier']\n","clf_list = [clf1, clf2, clf3, sclf]\n","    \n","fig = plt.figure(figsize = (10, 8))\n","gs = gridspec.GridSpec(2, 2)\n","grid = itertools.product([0, 1], repeat = 2)\n","\n","clf_cv_mean = []\n","clf_cv_std = []\n","for clf, label, grd in zip(clf_list, label, grid):\n","        \n","    scores = cross_val_score(clf, X, y, cv = 3, scoring = 'accuracy')\n","    print('Accuracy: %.2f (+/- %.2f) [%s]' % (scores.mean(), scores.std(), label))\n","    clf_cv_mean.append(scores.mean())\n","    clf_cv_std.append(scores.std())\n","        \n","    clf.fit(X, y)\n","    ax = plt.subplot(gs[grd[0], grd[1]])\n","    fig = plot_decision_regions(X = X, y = y, clf = clf)\n","    plt.title(label)\n","\n","plt.show()"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"TwqDtMdRqAkb","colab_type":"text"},"source":["The stacking ensemble is illustrated int the figure above. It consists of k-NN, Random Forest and Naive Bayes base classifiers whose predictions are combined by Lostic Regression as a meta-classifier. We can see the blending of decision boundaries achieved by the stacking classifier."]},{"cell_type":"code","metadata":{"id":"A34CQukFqAkd","colab_type":"code","colab":{}},"source":["# plot learning curves\n","X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.3, random_state = 33)\n","    \n","plt.figure()\n","plot_learning_curves(X_train, y_train, X_test, y_test, sclf, print_model = False, style = 'ggplot')\n","plt.show()"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"Q0oyWvfiqAki","colab_type":"text"},"source":["We can see that stacking achieves higher accuracy than individual classifiers and based on learning curves, it shows no signs of overfitting."]},{"cell_type":"code","metadata":{"id":"EQz98M7FqAkk","colab_type":"code","colab":{}},"source":["# plot classifier accuracy    \n","plt.figure()\n","(_, caps, _) = plt.errorbar(\n","    range(4),\n","    clf_cv_mean,\n","    yerr = clf_cv_std,\n","    c = 'blue',\n","    fmt = '-o',\n","    capsize = 5)\n","\n","for cap in caps:\n","    cap.set_markeredgewidth(1)                                                                                                                                \n","\n","plt.title('Stacking Ensemble')\n","plt.ylabel('Accuracy')\n","plt.xlabel('Classifier')\n","plt.xticks(range(4), ['KNN', 'RF', 'NB', 'Stacking'])     \n","plt.show()"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"IS5Tc4z9FoYy","colab_type":"text"},"source":[">"]},{"cell_type":"markdown","metadata":{"id":"mxI2We9OFpfs","colab_type":"text"},"source":[">"]},{"cell_type":"markdown","metadata":{"id":"81DoNxN1FqGN","colab_type":"text"},"source":[">"]},{"cell_type":"markdown","metadata":{"id":"RERADKgNFq9T","colab_type":"text"},"source":["\n","\n","---\n","\n","\n","\n","---\n","\n","\n","\n","> > > > > > > > > © 2019 Institute of Data\n","\n","\n","---\n","\n","\n","\n","---\n","\n","\n","\n"]}]}